{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import torch\n",
    "import numpy as np\n",
    "from hw1 import train_DNN, Utility_function,simulate_optimal_path\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.0257\n",
      "Epoch 0, Loss: 0.0082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.0233\n",
      "Epoch 0, Loss: 0.0885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 6.130s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# integration tests\n",
    "class TestIntegration(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\" initialize the model and parameters \"\"\"\n",
    "        self.T = 10\n",
    "        self.a = 1\n",
    "        self.p = 0.6\n",
    "        self.A = 0.1\n",
    "        self.B = -0.05\n",
    "        self.r = 0.02\n",
    "        self.W0 = np.random.uniform(1, 20)\n",
    "        self.model = train_DNN(self.T, self.a, self.p, self.A, self.B, self.r,self.W0, num_epochs=100)\n",
    "\n",
    "    def test_training_loss_decreasing(self):\n",
    "        \"\"\" make sure the training loss is decreasing \"\"\"\n",
    "        W_values = np.arange(1, 20.5, 0.5)\n",
    "        states, targets = [], []\n",
    "        max_W, min_W = 20.0, 1.0\n",
    "        # normalize the states\n",
    "        normalize = lambda t, W: np.array([t / self.T, (W - min_W) / (max_W - min_W)])\n",
    "\n",
    "        # generate the states and targets\n",
    "        for t in range(self.T):\n",
    "            for W in W_values:\n",
    "                states.append(normalize(t, W))\n",
    "                targets.append(Utility_function(W, self.a))  # calculate the target utility\n",
    "        \n",
    "        states = torch.FloatTensor(np.array(states)) # turn states into tensor\n",
    "        targets = torch.FloatTensor(np.array(targets)).unsqueeze(1) # turn targets into tensor\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        losses = []\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001) # use Adam optimizer\n",
    "\n",
    "        # train the model for 50 epochs\n",
    "        for _ in range(50):  \n",
    "            optimizer.zero_grad() # zero the gradients\n",
    "            outputs = self.model(states) # forward pass\n",
    "            loss = criterion(outputs, targets) # calculate the loss\n",
    "            loss.backward() # backward pass\n",
    "            optimizer.step() # update the weights\n",
    "            losses.append(loss.item()) # record the loss\n",
    "\n",
    "        # make sure the loss is decreasing\n",
    "        self.assertTrue(losses[-1] < losses[0]) \n",
    "\n",
    "    def test_simulate_optimal_path(self):\n",
    "        \"\"\" make sure the simulated optimal path is valid \"\"\"\n",
    "        actions, wealth = simulate_optimal_path(self.model, self.W0, self.T, self.p, self.A, self.B, self.r)\n",
    "\n",
    "        # make sure the actions are within the valid range\n",
    "        for x_t in actions:\n",
    "            self.assertTrue(0.0 <= x_t <= 1.0)\n",
    "\n",
    "        # make sure the wealth is not NaN or inf\n",
    "        for W_t in wealth:\n",
    "            self.assertFalse(np.isnan(W_t))\n",
    "            self.assertFalse(np.isinf(W_t))\n",
    "\n",
    "    def test_multiple_model_training(self):\n",
    "        \"\"\" make sure the two models are trained independently \"\"\"\n",
    "        model_1 = train_DNN(self.T, self.a, self.p, self.A, self.B, self.r, self.W0, num_epochs=100)\n",
    "        model_2 = train_DNN(self.T, self.a, self.p, self.A, self.B, self.r, self.W0, num_epochs=100)\n",
    "        optimizer_1 = torch.optim.Adam(model_1.parameters(), lr=0.001)\n",
    "        optimizer_2 = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "        # generate the states\n",
    "        W_values = np.arange(1, 20.5, 0.5)\n",
    "        states = [torch.FloatTensor([t / self.T, (W - 1) / (20 - 1)]) for t in range(self.T) for W in W_values]\n",
    "        states = torch.stack(states)\n",
    "\n",
    "        # train the two models\n",
    "        optimizer_1.zero_grad()\n",
    "        loss_1 = nn.MSELoss()(model_1(states), torch.zeros_like(model_1(states)))\n",
    "        loss_1.backward()\n",
    "        optimizer_1.step()\n",
    "\n",
    "        optimizer_2.zero_grad()\n",
    "        loss_2 = nn.MSELoss()(model_2(states), torch.zeros_like(model_2(states)))\n",
    "        loss_2.backward()\n",
    "        optimizer_2.step()\n",
    "\n",
    "        params_1 = [p.clone().detach() for p in model_1.parameters()]\n",
    "        params_2 = [p.clone().detach() for p in model_2.parameters()]\n",
    "\n",
    "        for p1, p2 in zip(params_1, params_2):\n",
    "            self.assertFalse(torch.equal(p1, p2))  # make sure the two models are trained independently\n",
    "\n",
    "# run the integration tests\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], exit=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
